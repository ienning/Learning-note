[TOC]

# 第一节：介绍用于视觉识别的CNN

 视觉的起源，视觉处理历史，视觉神经网络历史，ImageNet和Pascal介绍，人的视觉系统对识别画面的解析，理解图像

# 第二节：图像分类pipeline

## Nearest Neightbors 

描述：已知一定的验证集，实例A为待分类的，从验证集中计算与实例A相邻最近的实例，选择实例A属于哪个类别。

## K Nearest Neightbors 

描述：已知一定的验证集，实例A为待分类的，从验证集中计算与实例A相邻最近的K个实例，K个实例通过投票少数服从多数，

选择实例A属于哪个类别。

## Linear classificaition


$$
Y = W*X
$$


# 第三节：损失函数和优化

损失函数是用于评价W矩阵参数的，如果W效果差，可以进行后面的调整

## SVM

$$
L_i = \sum_{y_i!=y_j}max(0, S_{y_j}-S_{y_i}+1)
$$



## 第四节 

前向

反向传播

## 第五节 卷积神经网络

卷积层：卷积层使用卷积核进行滑动卷积，一般对在四边用0填充，以及增加pad，

池化：用于降采样操作，一般使用最大池化，不是滑动窗口方式滑动过去，滑动方式也能降采样

全连接层：通常作为卷积神经网络最后一层

sigmod：1/(1+e^-x)，

ReLU：max(0, X)，简单，运算快，收敛快，但是小于等于0的会被过滤了，如果改为max(ax, x)效果会好很多

tanh：以0为对称

参数不能过大也不能过大：过小会导致梯度消失（所以网络层数过多也容易梯度消失），过大导致网络饱和不收敛



# 第六节 训练神经网络上

## 1. 激活函数

sigmod：1/(1+e^-x)，

ReLU：max(0, X)，简单，运算快，收敛快，但是小于等于0的会被过滤了，如果改为max(ax, x)效果会好很多

tanh：以0为对称

## 2. 批量归一化

一般存在全连接层或卷积层之后

# 第七节 训练神经网络下

SGD优化，使用

## 1. 正则化

用于增加噪声

## 2. 迁移学习

在数据集比较少的，通过使用预训练模型。

# 第八节 深度学习软件

## 1.CPU vs GPU

## 2. TensorFlow

## 3. PyTorch

Pytorch能够动态调整网络，而TensorFlow是静态的。

# 第九节 CNN框架

1. AlexNet
2. VGG：层数比较多，参数多，占用内存大，但是效果
3. GoogleNet：通过使用bottleneck降低参数数量，以及模块方式，
4. ResNet：通过残差，防止层数过多导致梯度消失

# 第十节 循环神经网络

循环神经网络

CNN的输出可以和循环神经网络结合

LSTM：分为f，g，o，n

# 第十一节图像目标检测和图像分割

语义分割：对图像像素中每一个像素进行分类

有down polling和up polling，如果down polling知道在哪位置取最大值，那么up polling还原时候还原到对应位置。

上采样：使用转置卷积

目标检测：通过找感兴趣区域进行识别，通过传统算法找感兴趣区域，速度慢，通过Fast-RCNN找到速度快。还有YOLO，SSD等

物体分割：Mask R-CNN，结合目标检测以及分割

# 第十二节 可视化和理解

特征与像素是不同的。

# 第十三节 生成模型

无监督学习：

因为，没有外部loss了，所以需要知道数据隐藏的结构关系

Pixel RNN/CNN：RNN是从图像角开始的，通过输入数据找到最大似然，进行学习

autoencoder：通过Encoder找到输入数据x的最重要特征，然后通过解码器得到重构的数据X\' ，然后通过两个数据差计算loss进行训练

GAN：

# 第十四节 深度增强学习

# 第十五节 深度学习方法、硬件及对抗样本和

