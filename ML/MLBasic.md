# 机器学习基本算法

## K-近邻算法





## 决策树



## 朴素贝叶斯算法



## Logistics回归

## 支持向量机

## AdaBoost 

AdaBoost是adaptive boosting（自适应boosting）的缩写

- 优点：返回错误率低，易编码，可以应用在大部分分类器上，无参数调整
- 缺点：对离群点敏感
- 使用数据类型：数值型和标称型数据

### AdaBoost的一般流程

1. 收集数据：可以使用任意方法
2. 准备数据：依赖于所使用的的弱分类器类型，本章使用的是单层决策树，这种分类器可以处理任何数据类型。当然也可以使用任意分类器作为弱分类器。作为弱分类器，简单分类器的效果更好
3. 分析数据：可以使用任意方法
4. 训练算法：AdaBoost的大部分时间都用在训练上，分类器将多次在同一数据集上训练弱分类器。
5. 测试算法：计算分类的错误率
6. 使用算法：同SVM一样，AdaBoost预测两个类别中一个。如果想把它应用到多个类别的场合，那么就要像多类SVM中的做法一样对AdaBoost进行修改。

### 非均衡分类问题

#### 分类性能度量指标

- 正确率：公式为（真正例/(真正例+伪正例)）
- 召回率：公式为（真正例/(真正例+伪反例)）
- ROC曲线：代表接受者操作特征

### 基于代价函数的分类器决策控制

### 处理非均衡问题的数据抽样方法

- 欠抽样：删除样例
- 过抽样：复制样例

## 树回归

- 优点：可以对复杂和非线性的数据建模
- 缺点：结果不易理解
- 使用数据类型：数值型和标称型数据

### 树回归的一般方法

1. 收集数据：采用任意方法收据数据
2. 准备数据：需要数值型数据，标称型数据应该映射成二值型数据
3. 分析数据：绘出数据的二维可视化显示结果，以字典方式生成树
4. 训练算法：大部分时间都花费在叶节点树模型的构建上
5. 测试算法：使用测试数据上的R2值来分析模型的效果
6. 使用算法：使用训练出的树做预测，预测结果还可以用来做很多事情

## 感知机

## 隐马尔科夫模型

## 条件随机场



## K-均值聚类算法

### 优缺点

- 优点：容易实现
- 缺点：可能收敛到局部最小值，在大规模数据集上收敛较慢
- 使用数据类型：数值型数据

## Apriori算法

 ### 优缺点

- 优点：易编码实现
- 缺点：在大数据集上可能较慢
- 使用数据类型：数值型或标称型数据

### Apriori算法的一般过程

1. 收集数据：用任意方法
2. 准备数据：任何数据类型都可以，因为我们只保存集合
3. 分析数据：使用任意方法
4. 训练算法：使用spriori算法来找到频繁项集
5. 测试算法：不需要测试过程
6. 使用算法：用于发现频繁项集以及物品之间的关联规则

## FP-growth算法

### Introduction:

在互联网搜索任务中，将数据集存储在一个特定的称作FP数的结构之后发现频繁项集或者频繁项对，即常在一块出现的元素项的集合FP树。这种做法比Apriori算法的执行速度要快，性能通常在两个数量级上。FP-growth算法在寻找频繁项集上能够更好地发现，但是不能用于发现关联规则。

### 优缺点

- 优点：一般要求快于Apriori。
- 缺点：实现比较困难，在某些数据集上性能会下降。
- 使用数据类型：标称型数据。

### FP-growth的一般流程

1. 收集数据：使用任意方法
2. 准备数据：由于存储的是集合，所以需要离散数据。如果要处理连续数据，需要将它们量化为离散值。
3. 分析数据：使用任意方法
4. 训练算法：构建一个FP树，并对树进行挖掘
5. 测试算法：没有测试过程。
6. 使用算法：可用于识别经常出现的元素项，从而用于指定决策，推荐元素或进行预测等应用。

## 奇异值分解（SVD）

### 简介：

SVM是矩阵分解的一种，矩阵分解是将数据矩阵分解为多个独立部分的过程。SVD将原始的数据集矩阵Data分解为三个矩阵A，B，C。如果原始矩阵Data是m行n列，那么A、B和C分别就是m行m列，m行n列和n行n列。`【

### 优缺点：

- 优点：简化数据，去除噪声，提高算法的结果
- 缺点：数据的转换可能难以理解
- 使用数据类型：数值型数据。
- 



## 主成分分析（PCA）

#### 简介：

在PCA中，数据从原来的坐标系转换到了新的坐标系，新坐标系的选择是有数据本身决定的。第一个新坐标轴选择的是原始数据中方差最大的方向，第二个新坐标轴的选择和第一个坐标轴正交且具有最大方差的方向。该过程一直重复，重复次数为原始数据中特征的数目。

#### 优缺点：

- 优点：降低数据的复杂性，识别最重要的多个特征。
- 缺点：不一定需要，且可能损失有用信息。
- 使用数据类型：数值型数据。

### 因子分析

#### 简介：

因子分析也是一种降维技术，在因子分析中，我们假设在观察数据的生成中有一些观察不到的隐变量。假设观察数据是这些隐变量和某些噪声的线性组合。那么隐变量的数据可能比观察数据的数目少，也就是说通过找到隐变量就可以实现数据的降维。

### 独立成分分析

#### 简介：

ICA假设数据是N个数据源生成的，这一点和因子分析有些类似。假设数据为多个数据源的混合观察结果，这些数据源之间在统计上是相互独立的，而在PCA中只假设数据是不相关的。同因子分析一样，如果数据源的数目少于观察数据的数目，则可以实现降维过程。

## 潜在语义分析

## 概率潜在语义分析

## 马尔可夫链蒙特卡洛法

## 潜在狄利克雷分配

## PageRank算法

## 常用操作

### 数据缺失处理的一般处理方式：

- 使用可用特征的均值来填补缺失值
- 使用特殊值来填补失值，如-1
- 忽略有缺失值的样本
- 使用相似样本的均值填补缺失值
- 使用另外的机器学习算法预测缺失值

## 大数据与MapReduce

### MapReduce：分布式计算的框架

- 优点：可在短时间内完成大量工作。
- 缺点：算法必须经过重写，需要对系统工程有一定的理解
- 使用数据类型：数值型和标称型数据

#### 知识要点

- 主节点控制MapReduce的作业流程；
- MapReduce的作业可以分成map任务和reduce任务
- map任务之间不做数据交流，reduce任务也一样
- 在map和reduce阶段中间，有一个sort或combine阶段
- 数据被重复存放在不同的机器上，以防止某个机器失效
- mapper和reducer传输的数据形式为key/value对

### 在MapReduce框架上使用SVM的一般算法

1. 收集数据：数据按文本格式存放
2. 准备数据：输入数据已经是可用的格式，所以不需要任何准备工作。如果你需要解析一个大规模的数据集，建议使用map作业来完成，从而达到并行处理的目的
3. 分许数据：无
4. 训练算法：与普通的SVM一样，在分类器训练上仍需要花费大量时间
5. 测试算法：在二维空间上可视化后，观察超平面，判断算法是否有效。
6. 使用算法：本利不会展示一个完整的应用，但会展示如何在大数据集上训练SVM。该算法其中一个应用场景就是文本分类，通常在文本分类里可能有大量的文档和成千上万的特征。



